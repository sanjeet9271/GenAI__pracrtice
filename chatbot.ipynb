{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip==23.1.2 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (23.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (1.6.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 6)) (3.9.1)\n",
      "Requirement already satisfied: gensim in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (4.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\skumar10\\appdata\\roaming\\python\\python311\\site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 3)) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow->-r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\skumar10\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\skumar10\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\skumar10\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.31.0)\n",
      "Requirement already satisfied: click in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->-r requirements.txt (line 6)) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->-r requirements.txt (line 6)) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->-r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim->-r requirements.txt (line 7)) (7.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\skumar10\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk->-r requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\skumar10\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow->-r requirements.txt (line 5)) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\skumar10\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artificial intelligence o\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess_text(text_data):\n",
    "    data = text_data.lower()\n",
    "    data = re.sub(r'[^a-zA-Z0-9\\s.]','',data)\n",
    "    return data\n",
    "\n",
    "content = \"\"\n",
    "with open('dataset.txt','r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "data = preprocess_text(content)\n",
    "print(data[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "[['artificial', 'intelligence', 'or', 'ai', 'is', 'the', 'technology', 'behind', 'the', 'fourth', 'industrial', 'revolution', 'that', 'has', 'brought', 'great', 'changes', 'all', 'around', 'the', 'world'], ['it', 'is', 'usually', 'defined', 'as', 'the', 'study', 'of', 'intelligent', 'systems', 'that', 'could', 'execute', 'tasks', 'and', 'activities', 'that', 'would', 'require', 'human', 'level', 'intelligence'], ['similar', 'to', 'the', 'past', 'three', 'industrial', 'revolutions', 'ai', 'is', 'leaving', 'an', 'incredible', 'impact', 'on', 'productivity'], ['artificial', 'intelligence', 'ai', 'revolution', 'the', 'ai', 'revolution', 'has', 'fundamentally', 'changed', 'the', 'ways', 'people', 'collect', 'and', 'process', 'data', 'as', 'well', 'as', 'transformed', 'business', 'operations', 'across', 'different', 'industries'], ['in', 'general', 'ai', 'systems', 'are', 'supported', 'by', 'three', 'major', 'aspects', 'which', 'are', 'domain', 'knowledge', 'data', 'generation', 'and', 'machine', 'learning'], ['domain', 'knowledge', 'denotes', 'the', 'understanding', 'and', 'expertise', 'of', 'the', 'real', 'life', 'scenario', 'on', 'why', 'and', 'how', 'we', 'need', 'to', 'engineer', 'task'], ['the', 'data', 'aspect', 'refers', 'to', 'the', 'process', 'of', 'preparing', 'databases', 'required', 'to', 'feed', 'on', 'to', 'the', 'learning', 'algorithms'], ['lastly', 'machine', 'learning', 'detects', 'the', 'patterns', 'from', 'the', 'training', 'data', 'predicts', 'and', 'performs', 'tasks', 'without', 'being', 'manually', 'or', 'explicitly', 'programmed'], ['three', 'key', 'attributes', 'of', 'ai', 'technology'], ['intelligent', 'decision', 'making', 'the', 'simulation', 'of', 'human', 'intelligence', 'by', 'machines', 'can', 'infer', 'fast', 'solution', 'for', 'the', 'problems', 'that', 'are', 'often', 'faced', 'by', 'humanity'], ['ai', 'is', 'backed', 'by', 'advanced', 'data', 'analytics', 'and', 'machine', 'learning', 'which', 'means', 'ai', 'can', 'learn', 'and', 'gain', 'new', 'insights', 'as', 'it', 'keeps', 'feeding', 'on', 'new', 'data'], ['with', 'proper', 'input', 'ai', 'could', 'come', 'up', 'with', 'prompt', 'and', 'accurate', 'decisions'], ['in', 'addition', 'to', 'that', 'the', 'intelligence', 'attribute', 'of', 'ai', 'promotes', 'productivity', 'and', 'reduces', 'dependency', 'on', 'human', 'support', 'which', 'makes', 'ai', 'highly', 'autonomous', 'and', 'convenient', 'tool', 'to', 'have'], ['intentionality', 'intentionality', 'is', 'often', 'deemed', 'as', 'the', 'technical', 'and', 'ontological', 'attributes', 'of', 'computer', 'programs', 'that', 'derived', 'from', 'the', 'algorithms', 'and', 'knowledge', 'engineering'], ['this', 'attribute', 'can', 'be', 'interpreted', 'as', 'ais', 'capability', 'of', 'delivering', 'insights', 'from', 'the', 'real', 'time', 'information', 'and', 'reacting', 'in', 'the', 'way', 'similar', 'to', 'its', 'creators', 'and', 'users'], ['the', 'responses', 'usually', 'strongly', 'reflect', 'the', 'social', 'context', 'that', 'creator', 'and', 'users', 'are', 'in'], ['additionally', 'with', 'development', 'of', 'data', 'ingestion', 'storage', 'capacity', 'processing', 'speed', 'and', 'analytic', 'techniques', 'ai', 'gets', 'more', 'capable', 'of', 'responding', 'to', 'the', 'issues', 'with', 'increasing', 'sophistication'], ['this', 'very', 'much', 'differentiates', 'ai', 'with', 'the', 'fundamental', 'function', 'of', 'machines', 'that', 'merely', 'carry', 'out', 'predetermined', 'routines'], ['adaptability', 'and', 'prediction', 'machine', 'learning', 'facilitates', 'ai', 'to', 'discover', 'the', 'pattern', 'of', 'the', 'data', 'that', 'were', 'previously', 'programmed', 'which', 'enables', 'ais', 'capability', 'of', 'making', 'its', 'own', 'change', 'as', 'circumstances', 'change'], ['the', 'attribute', 'of', 'adaptability', 'profoundly', 'enhances', 'ais', 'prediction', 'and', 'decision', 'making'], ['one', 'of', 'the', 'commonly', 'seen', 'examples', 'is', 'gmails', 'smart', 'compose', 'feature', 'which', 'offers', 'the', 'use', 'of', 'personalised', 'suggestions', 'as', 'users', 'typing', 'sentence'], ['it', 'illustrates', 'how', 'ai', 'adapts', 'to', 'ones', 'personal', 'writing', 'pattern', 'and', 'delivers', 'appropriate', 'suggestions'], ['ai', 'in', 'the', 'business', 'undoubtedly', 'the', 'artificial', 'intelligence', 'revolutions', 'had', 'profoundly', 'impacted', 'the', 'way', 'businesses', 'operate'], ['the', 'most', 'common', 'practises', 'are', 'the', 'automation', 'of', 'repetitive', 'tasks', 'that', 'require', 'less', 'human', 'input'], ['however', 'with', 'the', 'consistent', 'improvement', 'of', 'algorithms', 'ai', 'technology', 'is', 'no', 'longer', 'only', 'limited', 'to', 'the', 'capability', 'of', 'expanding', 'productivity', 'but', 'also', 'becomes', 'necessary', 'tool', 'in', 'engaging', 'customers', 'providing', 'service', 'excellence', 'and', 'driving', 'innovation'], ['here', 'are', 'several', 'industrial', 'scenarios', 'to', 'demonstrate', 'how', 'ai', 'transformed', 'the', 'nature', 'and', 'scope', 'of', 'business', 'activities'], ['contact', 'center', 'the', 'contact', 'center', 'has', 'evolved', 'significantly', 'over', 'the', 'years', 'and', 'has', 'become', 'more', 'sophisticated', 'thanks', 'to', 'the', 'use', 'of', 'ai', 'automation'], ['we', 'can', 'see', 'technological', 'advancement', 'of', 'contact', 'centers', 'in', 'the', 'form', 'of', 'chatbots', 'and', 'talkbots', 'that', 'enables', 'availability', 'and', 'instant', 'response', 'for', 'consumer', 'engagement', 'at', 'scale'], ['changing', 'the', 'strategies', 'to', 'engage', 'customers', 'with', 'ai', 'based', 'automation', 'vastly', 'boost', 'service', 'capability', 'and', 'reduce', 'service', 'failures', 'that', 'are', 'usually', 'caused', 'by', 'underperforming', 'agents', 'or', 'emotional', 'labour'], ['while', 'human', 'agents', 'require', 'frequent', 'and', 'regular', 'customer', 'service', 'training', 'to', 'maintain', 'the', 'service', 'quality', 'ai', 'talkbot', 'learns', 'from', 'every', 'customer', 'interaction', 'and', 'keeps', 'improving', 'to', 'provide', 'excellent', 'service', 'over', 'time'], ['this', 'very', 'much', 'reduces', 'labour', 'cost', 'associated', 'with', 'performance', 'evaluation', 'and', 'contact', 'center', 'training'], ['furthermore', 'ai', 'systems', 'in', 'contact', 'centers', 'such', 'as', 'talkbot', 'have', 'the', 'capability', 'to', 'be', 'customized', 'to', 'deliver', 'more', 'personal', 'experience', 'through', 'goal', 'driven', 'dialogues', 'based', 'on', 'the', 'customer', 'data', 'and', 'business', 'metric'], ['in', 'other', 'words', 'talkbots', 'can', 'easily', 'do', 'upselling', 'and', 'cross', 'selling', 'if', 'they', 'are', 'given', 'sufficient', 'information', 'about', 'the', 'customers', 'and', 'the', 'business', 'plan'], ['even', 'without', 'any', 'customer', 'care', 'training', 'talkbots', 'can', 'conduct', 'sentiment', 'analysis', 'from', 'the', 'conversation', 'and', 'unlock', 'the', 'hidden', 'customer', 'data', 'in', 'customer', 'voice', 'calls'], ['this', 'in', 'turn', 'provides', 'great', 'insights', 'for', 'future', 'planning'], ['also', 'compared', 'to', 'the', 'traditional', 'contact', 'center', 'ai', 'systems', 'show', 'stronger', 'capabilities', 'in', 'collecting', 'information', 'from', 'each', 'call', 'which', 'are', 'used', 'to', 'generate', 'the', 'report', 'in', 'more', 'intelligent', 'manner', 'and', 'with', 'better', 'insights'], ['ecommerce', 'nowadays', 'the', 'ecommerce', 'market', 'is', 'highly', 'saturated', 'and', 'competitive'], ['top', 'commerce', 'companies', 'heavily', 'rely', 'on', 'ai', 'technology', 'to', 'better', 'understand', 'their', 'customers', 'and', 'to', 'give', 'their', 'customers', 'better', 'service', 'in', 'order', 'to', 'remain', 'competitive', 'and', 'profitable'], ['intelligent', 'product', 'recommendation', 'is', 'one', 'of', 'the', 'typical', 'applications', 'of', 'ai', 'in', 'the', 'ecommerce', 'industry'], ['this', 'is', 'realtime', 'application', 'of', 'an', 'ai', 'algorithm', 'that', 'attempts', 'to', 'figure', 'out', 'customers', 'preference', 'based', 'on', 'their', 'previous', 'purchases', 'researches', 'and', 'consumption', 'habits'], ['the', 'collected', 'insights', 'enable', 'ecommerce', 'companies', 'to', 'personalize', 'product', 'recommendations', 'for', 'different', 'online', 'shoppers'], ['to', 'certain', 'extent', 'it', 'enhances', 'the', 'shopping', 'experience', 'and', 'potentially', 'boosts', 'sales'], ['however', 'if', 'the', 'ecommerces', 'overuses', 'intelligent', 'product', 'recommendation', 'and', 'adopts', 'an', 'aggressive', 'marketing', 'strategy', 'the', 'reverse', 'effect', 'might', 'happen'], ['beyond', 'the', 'function', 'of', 'personalization', 'ecommerce', 'businesses', 'also', 'leverage', 'ai', 'technology', 'to', 'support', 'customer', 'service', 'through', 'chatbots', 'and', 'talkbots', 'to', 'assist', 'them', 'with', 'customer', 'care', 'inventory', 'management', 'via', 'demand', 'forecasting', 'or', 'product', 'promotion'], ['logistics', 'and', 'supply', 'chain', 'the', 'use', 'of', 'artificial', 'intelligence', 'and', 'machine', 'learning', 'has', 'fundamentally', 'transformed', 'supply', 'chain', 'management', 'and', 'delivered', 'strong', 'optimization', 'of', 'capabilities', 'associated', 'with', 'accurate', 'management', 'high', 'productivity', 'low', 'operating', 'cost', 'and', 'quick', 'delivery'], ['for', 'example', 'with', 'the', 'capability', 'of', 'handling', 'big', 'data', 'the', 'ai', 'technology', 'could', 'be', 'used', 'to', 'automates', 'the', 'workflow', 'of', 'inventory', 'management'], ['parcels', 'could', 'be', 'packed', 'and', 'sorted', 'in', 'seamless', 'process', 'at', 'large', 'scale', 'which', 'would', 'largely', 'reduce', 'processing', 'time', 'and', 'minimize', 'human', 'error'], ['also', 'the', 'ai', 'system', 'can', 'forecast', 'market', 'demand', 'from', 'the', 'market', 'and', 'purchase', 'histories', 'facilitating', 'the', 'prediction', 'of', 'the', 'future', 'sales', 'and', 'providing', 'information', 'to', 'support', 'resource', 'allocation'], ['moreover', 'ai', 'algorithms', 'are', 'also', 'being', 'used', 'to', 'optimize', 'the', 'shipping', 'and', 'delivery', 'route', 'with', 'some', 'of', 'the', 'most', 'advanced', 'ones', 'even', 'involving', 'the', 'prediction', 'and', 'management', 'of', 'traffic', 'lights'], ['overall', 'in', 'the', 'information', 'and', 'data', 'driven', 'era', 'the', 'potential', 'of', 'ai', 'is', 'tremendous'], ['business', 'process', 'automation', 'could', 'reduce', 'stress', 'on', 'internal', 'productivity', 'and', 'decrease', 'reliance', 'on', 'human', 'support', 'while', 'at', 'the', 'same', 'time', 'increase', 'operational', 'cost', 'efficiency'], ['machine', 'learning', 'enables', 'the', 'company', 'to', 'delve', 'into', 'more', 'intelligent', 'approach', 'and', 'continually', 'drives', 'the', 'evolution', 'business', 'model'], ['companies', 'should', 'prepare', 'themselves', 'for', 'the', 'ai', 'revolution', 'wave', 'so', 'they', 'can', 'leverage', 'on', 'the', 'technology', 'to', 'achieve', 'the', 'optimal', 'operational', 'excellence'], ['hi', 'how', 'are', 'you', 'doing', 'im', 'fine'], ['how', 'about', 'yourself', 'im', 'fine'], ['how', 'about', 'yourself', 'im', 'pretty', 'good'], ['thanks', 'for', 'asking'], ['im', 'pretty', 'good'], ['thanks', 'for', 'asking'], ['no', 'problem'], ['so', 'how', 'have', 'you', 'been', 'no', 'problem'], ['so', 'how', 'have', 'you', 'been', 'ive', 'been', 'great'], ['what', 'about', 'you', 'ive', 'been', 'great'], ['what', 'about', 'you', 'ive', 'been', 'good'], ['im', 'in', 'school', 'right', 'now'], ['ive', 'been', 'good'], ['im', 'in', 'school', 'right', 'now'], ['what', 'school', 'do', 'you', 'go', 'to', 'what', 'school', 'do', 'you', 'go', 'to', 'go', 'to', 'pcc'], ['go', 'to', 'pcc'], ['do', 'you', 'like', 'it', 'there', 'do', 'you', 'like', 'it', 'there', 'its', 'okay'], ['its', 'really', 'big', 'campus'], ['its', 'okay'], ['its', 'really', 'big', 'campus'], ['good', 'luck', 'with', 'school'], ['good', 'luck', 'with', 'school'], ['thank', 'you', 'very', 'much'], ['hows', 'it', 'going', 'im', 'doing', 'well'], ['how', 'about', 'you', 'im', 'doing', 'well'], ['how', 'about', 'you', 'never', 'better', 'thanks'], ['never', 'better', 'thanks'], ['so', 'how', 'have', 'you', 'been', 'lately', 'so', 'how', 'have', 'you', 'been', 'lately', 'ive', 'actually', 'been', 'pretty', 'good'], ['you', 'ive', 'actually', 'been', 'pretty', 'good'], ['you', 'im', 'actually', 'in', 'school', 'right', 'now'], ['im', 'actually', 'in', 'school', 'right', 'now'], ['which', 'school', 'do', 'you', 'attend', 'which', 'school', 'do', 'you', 'attend', 'im', 'attending', 'pcc', 'right', 'now'], ['im', 'attending', 'pcc', 'right', 'now'], ['are', 'you', 'enjoying', 'it', 'there', 'are', 'you', 'enjoying', 'it', 'there', 'its', 'not', 'bad'], ['there', 'are', 'lot', 'of', 'people', 'there'], ['its', 'not', 'bad'], ['there', 'are', 'lot', 'of', 'people', 'there'], ['good', 'luck', 'with', 'that'], ['good', 'luck', 'with', 'that'], ['thanks'], ['how', 'are', 'you', 'doing', 'today', 'im', 'doing', 'great'], ['what', 'about', 'you', 'im', 'doing', 'great'], ['what', 'about', 'you', 'im', 'absolutely', 'lovely', 'thank', 'you'], ['im', 'absolutely', 'lovely', 'thank', 'you'], ['everythings', 'been', 'good', 'with', 'you', 'everythings', 'been', 'good', 'with', 'you', 'havent', 'been', 'better'], ['how', 'about', 'yourself', 'havent', 'been', 'better'], ['how', 'about', 'yourself', 'started', 'school', 'recently'], ['started', 'school', 'recently'], ['where', 'are', 'you', 'going', 'to', 'school', 'where', 'are', 'you', 'going', 'to', 'school', 'im', 'going', 'to', 'pcc'], ['im', 'going', 'to', 'pcc'], ['how', 'do', 'you', 'like', 'it', 'so', 'far', 'how', 'do', 'you', 'like', 'it', 'so', 'far', 'like', 'it', 'so', 'far'], ['my', 'classes', 'are', 'pretty', 'good', 'right', 'now'], ['like', 'it', 'so', 'far'], ['my', 'classes', 'are', 'pretty', 'good', 'right', 'now'], ['wish', 'you', 'luck'], ['its', 'an', 'ugly', 'day', 'today'], ['know'], ['think', 'it', 'may', 'rain'], ['know'], ['think', 'it', 'may', 'rain'], ['its', 'the', 'middle', 'of', 'summer', 'it', 'shouldnt', 'rain', 'today'], ['its', 'the', 'middle', 'of', 'summer', 'it', 'shouldnt', 'rain', 'today'], ['that', 'would', 'be', 'weird'], ['that', 'would', 'be', 'weird'], ['yeah', 'especially', 'since', 'its', 'ninety', 'degrees', 'outside'], ['yeah', 'especially', 'since', 'its', 'ninety', 'degrees', 'outside'], ['know', 'it', 'would', 'be', 'horrible', 'if', 'it', 'rained', 'and', 'it', 'was', 'hot', 'outside'], ['know', 'it', 'would', 'be', 'horrible', 'if', 'it', 'rained', 'and', 'it', 'was', 'hot', 'outside'], ['yes', 'it', 'would', 'be'], ['yes', 'it', 'would', 'be'], ['really', 'wish', 'it', 'wasnt', 'so', 'hot', 'every', 'day'], ['really', 'wish', 'it', 'wasnt', 'so', 'hot', 'every', 'day'], ['me', 'too'], ['cant', 'wait', 'until', 'winter'], ['me', 'too'], ['cant', 'wait', 'until', 'winter'], ['like', 'winter', 'too', 'but', 'sometimes', 'it', 'gets', 'too', 'cold'], ['like', 'winter', 'too', 'but', 'sometimes', 'it', 'gets', 'too', 'cold'], ['id', 'rather', 'be', 'cold', 'than', 'hot'], ['id', 'rather', 'be', 'cold', 'than', 'hot'], ['me', 'too'], ['it', 'doesnt', 'look', 'very', 'nice', 'outside', 'today'], ['youre', 'right'], ['think', 'its', 'going', 'to', 'rain', 'later'], ['youre', 'right'], ['think', 'its', 'going', 'to', 'rain', 'later'], ['in', 'the', 'middle', 'of', 'the', 'summer', 'it', 'shouldnt', 'be', 'raining'], ['in', 'the', 'middle', 'of', 'the', 'summer', 'it', 'shouldnt', 'be', 'raining'], ['that', 'wouldnt', 'seem', 'right'], ['that', 'wouldnt', 'seem', 'right'], ['considering', 'that', 'its', 'over', 'ninety', 'degrees', 'outside', 'that', 'would', 'be', 'weird'], ['considering', 'that', 'its', 'over', 'ninety', 'degrees', 'outside', 'that', 'would', 'be', 'weird'], ['exactly', 'it', 'wouldnt', 'be', 'nice', 'if', 'it', 'started', 'raining'], ['its', 'too', 'hot'], ['exactly', 'it', 'wouldnt', 'be', 'nice', 'if', 'it', 'started', 'raining'], ['its', 'too', 'hot'], ['know', 'youre', 'absolutely', 'right'], ['know', 'youre', 'absolutely', 'right'], ['wish', 'it', 'would', 'cool', 'off', 'one', 'day'], ['wish', 'it', 'would', 'cool', 'off', 'one', 'day'], ['thats', 'how', 'feel', 'want', 'winter', 'to', 'come', 'soon'], ['thats', 'how', 'feel', 'want', 'winter', 'to', 'come', 'soon'], ['enjoy', 'the', 'winter', 'but', 'it', 'gets', 'really', 'cold', 'sometimes'], ['enjoy', 'the', 'winter', 'but', 'it', 'gets', 'really', 'cold', 'sometimes'], ['know', 'what', 'you', 'mean', 'but', 'id', 'rather', 'be', 'cold', 'than', 'hot'], ['know', 'what', 'you', 'mean', 'but', 'id', 'rather', 'be', 'cold', 'than', 'hot'], ['thats', 'exactly', 'how', 'feel'], ['wish', 'it', 'was', 'nicer', 'day', 'today'], ['that', 'is', 'true'], ['hope', 'it', 'doesnt', 'rain'], ['that', 'is', 'true'], ['hope', 'it', 'doesnt', 'rain'], ['it', 'wouldnt', 'rain', 'in', 'the', 'middle', 'of', 'the', 'summer'], ['it', 'wouldnt', 'rain', 'in', 'the', 'middle', 'of', 'the', 'summer'], ['it', 'wouldnt', 'seem', 'right', 'if', 'it', 'started', 'raining', 'right', 'now'], ['it', 'wouldnt', 'seem', 'right', 'if', 'it', 'started', 'raining', 'right', 'now'], ['it', 'would', 'be', 'weird', 'if', 'it', 'started', 'raining', 'in', 'ninety', 'degree', 'weather'], ['it', 'would', 'be', 'weird', 'if', 'it', 'started', 'raining', 'in', 'ninety', 'degree', 'weather'], ['any', 'rain', 'right', 'now', 'would', 'be', 'pointless'], ['any', 'rain', 'right', 'now', 'would', 'be', 'pointless'], ['thats', 'right', 'it', 'really', 'would', 'be'], ['thats', 'right', 'it', 'really', 'would', 'be'], ['want', 'it', 'to', 'cool', 'down', 'some'], ['want', 'it', 'to', 'cool', 'down', 'some'], ['know', 'what', 'you', 'mean', 'cant', 'wait', 'until', 'its', 'winter'], ['know', 'what', 'you', 'mean', 'cant', 'wait', 'until', 'its', 'winter'], ['winter', 'is', 'great'], ['wish', 'it', 'didnt', 'get', 'so', 'cold', 'sometimes', 'though'], ['winter', 'is', 'great'], ['wish', 'it', 'didnt', 'get', 'so', 'cold', 'sometimes', 'though'], ['would', 'rather', 'deal', 'with', 'the', 'winter', 'than', 'the', 'summer'], ['its', 'such', 'nice', 'day'], ['yes', 'it', 'is'], ['yes', 'it', 'is'], ['it', 'looks', 'like', 'it', 'may', 'rain', 'soon'], ['it', 'looks', 'like', 'it', 'may', 'rain', 'soon'], ['yes', 'and', 'hope', 'that', 'it', 'does'], ['yes', 'and', 'hope', 'that', 'it', 'does'], ['why', 'is', 'that', 'why', 'is', 'that', 'really', 'love', 'how', 'rain', 'clears', 'the', 'air'], ['really', 'love', 'how', 'rain', 'clears', 'the', 'air'], ['me', 'too'], ['it', 'always', 'smells', 'so', 'fresh', 'after', 'it', 'rains'], ['me', 'too'], ['it', 'always', 'smells', 'so', 'fresh', 'after', 'it', 'rains'], ['yes', 'but', 'love', 'the', 'night', 'air', 'after', 'it', 'rains'], ['yes', 'but', 'love', 'the', 'night', 'air', 'after', 'it', 'rains'], ['really', 'why', 'is', 'it', 'really', 'why', 'is', 'it', 'because', 'you', 'can', 'see', 'the', 'stars', 'perfectly'], ['because', 'you', 'can', 'see', 'the', 'stars', 'perfectly'], ['really', 'hope', 'it', 'rains', 'today'], ['really', 'hope', 'it', 'rains', 'today'], ['yeah', 'me', 'too'], ['isnt', 'it', 'nice', 'day', 'it', 'really', 'is'], ['it', 'really', 'is'], ['it', 'seems', 'that', 'it', 'may', 'rain', 'today'], ['it', 'seems', 'that', 'it', 'may', 'rain', 'today'], ['hopefully', 'it', 'will'], ['hopefully', 'it', 'will'], ['how', 'come', 'how', 'come', 'like', 'how', 'clear', 'the', 'sky', 'gets', 'after', 'it', 'rains'], ['like', 'how', 'clear', 'the', 'sky', 'gets', 'after', 'it', 'rains'], ['feel', 'the', 'same', 'way'], ['it', 'smells', 'so', 'good', 'after', 'it', 'rains'], ['feel', 'the', 'same', 'way'], ['it', 'smells', 'so', 'good', 'after', 'it', 'rains'], ['especially', 'love', 'the', 'night', 'air', 'when', 'it', 'rains'], ['especially', 'love', 'the', 'night', 'air', 'when', 'it', 'rains'], ['really', 'why', 'really', 'why', 'the', 'stars', 'look', 'so', 'much', 'closer', 'after', 'it', 'rains'], ['the', 'stars', 'look', 'so', 'much', 'closer', 'after', 'it', 'rains'], ['really', 'want', 'it', 'to', 'rain', 'today'], ['really', 'want', 'it', 'to', 'rain', 'today'], ['yeah', 'so', 'do'], ['dont', 'you', 'think', 'its', 'nice', 'out', 'yes', 'think', 'so', 'too'], ['yes', 'think', 'so', 'too'], ['think', 'that', 'its', 'going', 'to', 'rain'], ['think', 'that', 'its', 'going', 'to', 'rain'], ['hope', 'that', 'it', 'does', 'rain'], ['hope', 'that', 'it', 'does', 'rain'], ['you', 'like', 'the', 'rain', 'you', 'like', 'the', 'rain', 'the', 'sky', 'looks', 'so', 'clean', 'after', 'it', 'rains'], ['love', 'it'], ['the', 'sky', 'looks', 'so', 'clean', 'after', 'it', 'rains'], ['love', 'it'], ['understand'], ['rain', 'does', 'make', 'it', 'smell', 'cleaner'], ['understand'], ['rain', 'does', 'make', 'it', 'smell', 'cleaner'], ['love', 'most', 'how', 'it', 'is', 'at', 'night', 'after', 'it', 'rains'], ['love', 'most', 'how', 'it', 'is', 'at', 'night', 'after', 'it', 'rains'], ['how', 'come', 'how', 'come', 'you', 'can', 'see', 'the', 'stars', 'so', 'much', 'more', 'clearly', 'after', 'it', 'rains'], ['you', 'can', 'see', 'the', 'stars', 'so', 'much', 'more', 'clearly', 'after', 'it', 'rains'], ['would', 'love', 'for', 'it', 'to', 'rain', 'today'], ['really', 'want', 'to', 'go', 'to', 'the', 'beach', 'this', 'weekend'], ['that', 'sounds', 'like', 'fun'], ['whats', 'the', 'weather', 'going', 'to', 'be', 'like', 'that', 'sounds', 'like', 'fun'], ['whats', 'the', 'weather', 'going', 'to', 'be', 'like', 'heard', 'that', 'its', 'going', 'to', 'be', 'warm', 'this', 'weekend'], ['heard', 'that', 'its', 'going', 'to', 'be', 'warm', 'this', 'weekend'], ['is', 'it', 'going', 'to', 'be', 'perfect', 'beach', 'weather', 'is', 'it', 'going', 'to', 'be', 'perfect', 'beach', 'weather', 'believe', 'so'], ['believe', 'so'], ['good'], ['hope', 'it', 'doesnt', 'cool', 'off', 'this', 'weekend'], ['good'], ['hope', 'it', 'doesnt', 'cool', 'off', 'this', 'weekend'], ['know'], ['really', 'want', 'to', 'go', 'to', 'the', 'beach'], ['know'], ['really', 'want', 'to', 'go', 'to', 'the', 'beach'], ['but', 'you', 'know', 'that', 'california', 'weather', 'is', 'really', 'unpredictable'], ['but', 'you', 'know', 'that', 'california', 'weather', 'is', 'really', 'unpredictable'], ['youre', 'right'], ['one', 'minute', 'its', 'hot', 'and', 'then', 'the', 'next', 'minute', 'its', 'cold'], ['youre', 'right'], ['one', 'minute', 'its', 'hot', 'and', 'then', 'the', 'next', 'minute', 'its', 'cold'], ['really', 'wish', 'the', 'weather', 'would', 'just', 'stay', 'the', 'same'], ['really', 'wish', 'the', 'weather', 'would', 'just', 'stay', 'the', 'same'], ['do', 'too'], ['that', 'way', 'we', 'can', 'have', 'our', 'activities', 'planned', 'ahead', 'of', 'time'], ['do', 'too'], ['that', 'way', 'we', 'can', 'have', 'our', 'activities', 'planned', 'ahead', 'of', 'time'], ['yeah', 'that', 'would', 'make', 'things', 'lot', 'easier'], ['would', 'like', 'to', 'take', 'trip', 'to', 'the', 'beach', 'this', 'weekend'], ['trip', 'to', 'the', 'beach', 'would', 'be', 'fun'], ['how', 'is', 'the', 'weather', 'going', 'to', 'be', 'trip', 'to', 'the', 'beach', 'would', 'be', 'fun'], ['how', 'is', 'the', 'weather', 'going', 'to', 'be', 'the', 'forecast', 'says', 'that', 'it', 'will', 'be', 'warm', 'on', 'the', 'weekend'], ['the', 'forecast', 'says', 'that', 'it', 'will', 'be', 'warm', 'on', 'the', 'weekend'], ['so', 'do', 'you', 'think', 'itll', 'be', 'perfect', 'weather', 'for', 'the', 'beach', 'so', 'do', 'you', 'think', 'itll', 'be', 'perfect', 'weather', 'for', 'the', 'beach', 'it', 'sounds', 'like', 'it', 'will', 'be'], ['it', 'sounds', 'like', 'it', 'will', 'be'], ['really', 'hope', 'it', 'doesnt', 'get', 'cold'], ['really', 'hope', 'it', 'doesnt', 'get', 'cold'], ['that', 'would', 'ruin', 'things', 'want', 'to', 'go', 'so', 'badly'], ['that', 'would', 'ruin', 'things', 'want', 'to', 'go', 'so', 'badly'], ['the', 'weather', 'in', 'california', 'is', 'unpredictable', 'so', 'you', 'never', 'know'], ['the', 'weather', 'in', 'california', 'is', 'unpredictable', 'so', 'you', 'never', 'know'], ['that', 'is', 'true'], ['the', 'weather', 'is', 'constantly', 'changing'], ['that', 'is', 'true'], ['the', 'weather', 'is', 'constantly', 'changing'], ['it', 'would', 'be', 'nice', 'if', 'the', 'weather', 'would', 'never', 'change'], ['it', 'would', 'be', 'nice', 'if', 'the', 'weather', 'would', 'never', 'change'], ['that', 'would', 'be', 'great', 'then', 'we', 'could', 'plan', 'things', 'sooner'], ['that', 'would', 'be', 'great', 'then', 'we', 'could', 'plan', 'things', 'sooner'], ['true'], ['predictable', 'weather', 'would', 'make', 'life', 'easier'], ['it', 'would', 'be', 'nice', 'to', 'go', 'to', 'the', 'beach', 'sometime', 'this', 'weekend'], ['whats', 'the', 'weather', 'going', 'to', 'be', 'like', 'may', 'want', 'to', 'go', 'too'], ['whats', 'the', 'weather', 'going', 'to', 'be', 'like', 'may', 'want', 'to', 'go', 'too'], ['the', 'weather', 'this', 'weekend', 'is', 'supposed', 'to', 'be', 'warm'], ['the', 'weather', 'this', 'weekend', 'is', 'supposed', 'to', 'be', 'warm'], ['will', 'it', 'be', 'good', 'beach', 'weather', 'will', 'it', 'be', 'good', 'beach', 'weather', 'think', 'it', 'will', 'be'], ['think', 'it', 'will', 'be'], ['it', 'wouldnt', 'be', 'good', 'if', 'it', 'got', 'cold', 'this', 'weekend'], ['it', 'wouldnt', 'be', 'good', 'if', 'it', 'got', 'cold', 'this', 'weekend'], ['want', 'this', 'trip', 'to', 'be', 'perfect', 'hope', 'it', 'stays', 'warm'], ['want', 'this', 'trip', 'to', 'be', 'perfect', 'hope', 'it', 'stays', 'warm'], ['this', 'california', 'weather', 'is', 'so', 'uncertain', 'its', 'impossible', 'to', 'know', 'whatll', 'happen'], ['this', 'california', 'weather', 'is', 'so', 'uncertain', 'its', 'impossible', 'to', 'know', 'whatll', 'happen'], ['know'], ['every', 'day', 'the', 'weather', 'seems', 'different'], ['know'], ['every', 'day', 'the', 'weather', 'seems', 'different'], ['would', 'love', 'it', 'if', 'it', 'wasnt', 'always', 'so', 'unpredictable'], ['would', 'love', 'it', 'if', 'it', 'wasnt', 'always', 'so', 'unpredictable'], ['that', 'would', 'make', 'it', 'easier', 'for', 'us', 'to', 'make', 'plans'], ['hello', 'may', 'speak', 'to', 'alice', 'please', 'this', 'is']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess # type: ignore\n",
    "sentence_list = data.split('.')\n",
    "processed_data = [simple_preprocess(sentence) for sentence in sentence_list ] \n",
    "print(len(processed_data))\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0, 'it': 1, 'to': 2, 'and': 3, 'be': 4, 'that': 5, 'you': 6, 'of': 7, 'is': 8, 'would': 9, 'so': 10, 'its': 11, 'ai': 12, 'how': 13, 'weather': 14, 'really': 15, 'in': 16, 'rain': 17, 'right': 18, 'like': 19, 'good': 20, 'this': 21, 'are': 22, 'with': 23, 'rains': 24, 'know': 25, 'going': 26, 'im': 27, 'too': 28, 'after': 29, 'cold': 30, 'if': 31, 'want': 32, 'been': 33, 'can': 34, 'school': 35, 'hope': 36, 'do': 37, 'beach': 38, 'on': 39, 'think': 40, 'love': 41, 'weekend': 42, 'today': 43, 'winter': 44, 'hot': 45, 'go': 46, 'now': 47, 'for': 48, 'data': 49, 'but': 50, 'about': 51, 'day': 52, 'great': 53, 'wouldnt': 54, 'will': 55, 'wish': 56, 'what': 57, 'yes': 58, 'as': 59, 'nice': 60, 'may': 61, 'which': 62, 'customer': 63, 'have': 64, 'raining': 65, 'service': 66, 'there': 67, 'warm': 68, 'started': 69, 'why': 70, 'come': 71, 'summer': 72, 'doesnt': 73, 'from': 74, 'learning': 75, 'outside': 76, 'gets': 77, 'intelligence': 78, 'technology': 79, 'better': 80, 'more': 81, 'could': 82, 'human': 83, 'business': 84, 'much': 85, 'machine': 86, 'ninety': 87, 'unpredictable': 88, 'doing': 89, 'thanks': 90, 'sometimes': 91, 'never': 92, 'pretty': 93, 'perfect': 94, 'me': 95, 'intelligent': 96, 'we': 97, 'california': 98, 'customers': 99, 'contact': 100, 'middle': 101, 'does': 102, 'time': 103, 'capability': 104, 'air': 105, 'night': 106, 'ive': 107, 'weird': 108, 'stars': 109, 'cool': 110, 'one': 111, 'make': 112, 'pcc': 113, 'youre': 114, 'way': 115, 'yeah': 116, 'luck': 117, 'insights': 118, 'same': 119, 'at': 120, 'productivity': 121, 'rather': 122, 'things': 123, 'every': 124, 'management': 125, 'trip': 126, 'see': 127, 'by': 128, 'has': 129, 'information': 130, 'true': 131, 'feel': 132, 'thats': 133, 'ecommerce': 134, 'than': 135, 'also': 136, 'yourself': 137, 'talkbots': 138, 'automation': 139, 'over': 140, 'center': 141, 'most': 142, 'change': 143, 'prediction': 144, 'very': 145, 'actually': 146, 'support': 147, 'artificial': 148, 'product': 149, 'sky': 150, 'soon': 151, 'cant': 152, 'until': 153, 'id': 154, 'process': 155, 'activities': 156, 'seem': 157, 'off': 158, 'revolution': 159, 'algorithms': 160, 'mean': 161, 'seems': 162, 'get': 163, 'systems': 164, 'looks': 165, 'always': 166, 'smells': 167, 'wasnt': 168, 'wait': 169, 'degrees': 170, 'far': 171, 'then': 172, 'absolutely': 173, 'minute': 174, 'whats': 175, 'fun': 176, 'sounds': 177, 'or': 178, 'different': 179, 'training': 180, 'especially': 181, 'shouldnt': 182, 'an': 183, 'well': 184, 'changing': 185, 'forecast': 186, 'big': 187, 'out': 188, 'three': 189, 'enables': 190, 'reduce': 191, 'tasks': 192, 'people': 193, 'based': 194, 'some': 195, 'no': 196, 'use': 197, 'cost': 198, 'easier': 199, 'transformed': 200, 'usually': 201, 'attribute': 202, 'thank': 203, 'was': 204, 'industrial': 205, 'market': 206, 'users': 207, 'look': 208, 'making': 209, 'any': 210, 'exactly': 211, 'companies': 212, 'plan': 213, 'ais': 214, 'understand': 215, 'happen': 216, 'knowledge': 217, 'lot': 218, 'require': 219, 'their': 220, 'used': 221, 'agents': 222, 'competitive': 223, 'driven': 224, 'capabilities': 225, 'labour': 226, 'future': 227, 'while': 228, 'care': 229, 'talkbot': 230, 'even': 231, 'associated': 232, 'such': 233, 'experience': 234, 'through': 235, 'scale': 236, 'new': 237, 'similar': 238, 'domain': 239, 'life': 240, 'intentionality': 241, 'tool': 242, 'highly': 243, 'reduces': 244, 'accurate': 245, 'without': 246, 'being': 247, 'recommendation': 248, 'attributes': 249, 'input': 250, 'decision': 251, 'machines': 252, 'keeps': 253, 'often': 254, 'real': 255, 'processing': 256, 'chatbots': 257, 'function': 258, 'centers': 259, 'excellence': 260, 'providing': 261, 'revolutions': 262, 'fundamentally': 263, 'however': 264, 'businesses': 265, 'personal': 266, 'ones': 267, 'suggestions': 268, 'advanced': 269, 'enhances': 270, 'profoundly': 271, 'pattern': 272, 'adaptability': 273, 'programmed': 274, 'they': 275, 'lately': 276, 'because': 277, 'my': 278, 'perfectly': 279, 'hopefully': 280, 'clear': 281, 'when': 282, 'closer': 283, 'where': 284, 'recently': 285, 'clean': 286, 'smell': 287, 'havent': 288, 'cleaner': 289, 'clearly': 290, 'heard': 291, 'lovely': 292, 'classes': 293, 'fresh': 294, 'next': 295, 'clears': 296, 'rained': 297, 'inventory': 298, 'later': 299, 'considering': 300, 'enjoy': 301, 'leverage': 302, 'horrible': 303, 'degree': 304, 'pointless': 305, 'down': 306, 'didnt': 307, 'though': 308, 'since': 309, 'supply': 310, 'chain': 311, 'believe': 312, 'everythings': 313, 'bad': 314, 'sooner': 315, 'enjoying': 316, 'just': 317, 'delivery': 318, 'asking': 319, 'supposed': 320, 'got': 321, 'stays': 322, 'uncertain': 323, 'attending': 324, 'problem': 325, 'impossible': 326, 'whatll': 327, 'okay': 328, 'campus': 329, 'attend': 330, 'not': 331, 'demand': 332, 'sales': 333, 'ruin': 334, 'ahead': 335, 'fine': 336, 'says': 337, 'our': 338, 'stay': 339, 'itll': 340, 'planned': 341, 'badly': 342, 'operational': 343, 'constantly': 344, 'ontological': 345, 'derived': 346, 'proper': 347, 'computer': 348, 'programs': 349, 'technical': 350, 'hi': 351, 'deemed': 352, 'makes': 353, 'promotes': 354, 'prepare': 355, 'themselves': 356, 'addition': 357, 'wave': 358, 'dependency': 359, 'up': 360, 'convenient': 361, 'prompt': 362, 'optimal': 363, 'achieve': 364, 'decisions': 365, 'autonomous': 366, 'recommendations': 367, 'engineering': 368, 'should': 369, 'capacity': 370, 'efficiency': 371, 'speed': 372, 'analytic': 373, 'techniques': 374, 'increase': 375, 'capable': 376, 'responding': 377, 'issues': 378, 'increasing': 379, 'sophistication': 380, 'reliance': 381, 'decrease': 382, 'differentiates': 383, 'fundamental': 384, 'internal': 385, 'merely': 386, 'carry': 387, 'stress': 388, 'storage': 389, 'ingestion': 390, 'development': 391, 'feeding': 392, 'model': 393, 'interpreted': 394, 'evolution': 395, 'drives': 396, 'delivering': 397, 'continually': 398, 'approach': 399, 'reacting': 400, 'delve': 401, 'additionally': 402, 'creators': 403, 'company': 404, 'responses': 405, 'strongly': 406, 'reflect': 407, 'social': 408, 'context': 409, 'creator': 410, 'into': 411, 'predicts': 412, 'hows': 413, 'aspects': 414, 'past': 415, 'leaving': 416, 'incredible': 417, 'impact': 418, 'dont': 419, 'changed': 420, 'ways': 421, 'collect': 422, 'isnt': 423, 'operations': 424, 'across': 425, 'industries': 426, 'general': 427, 'supported': 428, 'deal': 429, 'level': 430, 'take': 431, 'execute': 432, 'brought': 433, 'speak': 434, 'hello': 435, 'plans': 436, 'us': 437, 'behind': 438, 'fourth': 439, 'sometime': 440, 'study': 441, 'changes': 442, 'all': 443, 'around': 444, 'world': 445, 'predictable': 446, 'defined': 447, 'major': 448, 'generation': 449, 'gain': 450, 'denotes': 451, 'performs': 452, 'manually': 453, 'explicitly': 454, 'key': 455, 'simulation': 456, 'infer': 457, 'fast': 458, 'solution': 459, 'problems': 460, 'faced': 461, 'humanity': 462, 'backed': 463, 'analytics': 464, 'means': 465, 'learn': 466, 'routines': 467, 'ugly': 468, 'patterns': 469, 'task': 470, 'understanding': 471, 'expertise': 472, 'nicer': 473, 'scenario': 474, 'need': 475, 'engineer': 476, 'aspect': 477, 'detects': 478, 'refers': 479, 'preparing': 480, 'databases': 481, 'required': 482, 'feed': 483, 'lastly': 484, 'predetermined': 485, 'discover': 486, 'tremendous': 487, 'might': 488, 'words': 489, 'easily': 490, 'personalization': 491, 'upselling': 492, 'cross': 493, 'selling': 494, 'beyond': 495, 'alice': 496, 'given': 497, 'sufficient': 498, 'effect': 499, 'turn': 500, 'reverse': 501, 'strategy': 502, 'marketing': 503, 'conduct': 504, 'sentiment': 505, 'analysis': 506, 'conversation': 507, 'unlock': 508, 'hidden': 509, 'voice': 510, 'other': 511, 'metric': 512, 'dialogues': 513, 'goal': 514, 'emotional': 515, 'frequent': 516, 'regular': 517, 'logistics': 518, 'maintain': 519, 'quality': 520, 'promotion': 521, 'learns': 522, 'forecasting': 523, 'interaction': 524, 'improving': 525, 'provide': 526, 'excellent': 527, 'via': 528, 'performance': 529, 'evaluation': 530, 'furthermore': 531, 'customized': 532, 'deliver': 533, 'them': 534, 'assist': 535, 'calls': 536, 'provides': 537, 'potential': 538, 'application': 539, 'give': 540, 'order': 541, 'remain': 542, 'profitable': 543, 'shoppers': 544, 'online': 545, 'typical': 546, 'applications': 547, 'industry': 548, 'realtime': 549, 'algorithm': 550, 'aggressive': 551, 'attempts': 552, 'figure': 553, 'preference': 554, 'previous': 555, 'purchases': 556, 'researches': 557, 'consumption': 558, 'habits': 559, 'collected': 560, 'enable': 561, 'certain': 562, 'extent': 563, 'rely': 564, 'heavily': 565, 'planning': 566, 'compared': 567, 'traditional': 568, 'show': 569, 'stronger': 570, 'adopts': 571, 'collecting': 572, 'each': 573, 'call': 574, 'overuses': 575, 'generate': 576, 'report': 577, 'manner': 578, 'ecommerces': 579, 'nowadays': 580, 'boosts': 581, 'saturated': 582, 'potentially': 583, 'top': 584, 'commerce': 585, 'shopping': 586, 'delivered': 587, 'underperforming': 588, 'caused': 589, 'resource': 590, 'illustrates': 591, 'adapts': 592, 'moreover': 593, 'allocation': 594, 'writing': 595, 'delivers': 596, 'appropriate': 597, 'undoubtedly': 598, 'had': 599, 'impacted': 600, 'operate': 601, 'failures': 602, 'facilitating': 603, 'common': 604, 'practises': 605, 'histories': 606, 'repetitive': 607, 'less': 608, 'purchase': 609, 'consistent': 610, 'improvement': 611, 'system': 612, 'sentence': 613, 'typing': 614, 'optimize': 615, 'personalised': 616, 'facilitates': 617, 'personalize': 618, 'era': 619, 'were': 620, 'previously': 621, 'overall': 622, 'own': 623, 'lights': 624, 'circumstances': 625, 'traffic': 626, 'involving': 627, 'route': 628, 'commonly': 629, 'seen': 630, 'examples': 631, 'gmails': 632, 'smart': 633, 'compose': 634, 'feature': 635, 'offers': 636, 'shipping': 637, 'longer': 638, 'only': 639, 'limited': 640, 'become': 641, 'automates': 642, 'handling': 643, 'technological': 644, 'advancement': 645, 'example': 646, 'form': 647, 'quick': 648, 'availability': 649, 'instant': 650, 'response': 651, 'consumer': 652, 'engagement': 653, 'operating': 654, 'low': 655, 'high': 656, 'strategies': 657, 'engage': 658, 'optimization': 659, 'vastly': 660, 'boost': 661, 'strong': 662, 'sophisticated': 663, 'years': 664, 'expanding': 665, 'workflow': 666, 'error': 667, 'minimize': 668, 'becomes': 669, 'necessary': 670, 'engaging': 671, 'largely': 672, 'large': 673, 'seamless': 674, 'sorted': 675, 'driving': 676, 'innovation': 677, 'here': 678, 'several': 679, 'scenarios': 680, 'demonstrate': 681, 'nature': 682, 'scope': 683, 'packed': 684, 'parcels': 685, 'evolved': 686, 'significantly': 687, 'please': 688}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec# type: ignore\n",
    "text_model = Word2Vec(sentences = processed_data,vector_size=500,window=10,min_count = 1,workers=4)\n",
    "print(text_model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.33008126e-03  1.17071359e-04  2.47741374e-03 ...  7.74717133e-04\n",
      "    5.55774779e-04 -1.87407364e-03]\n",
      "  [-1.62004877e-03  1.47978694e-03  1.32636435e-03 ...  1.06064812e-03\n",
      "    5.60025364e-05 -1.73412461e-03]\n",
      "  [-5.01271978e-04  1.70559785e-03  1.08401780e-03 ...  8.30922218e-04\n",
      "    2.77503568e-04 -2.25539017e-03]\n",
      "  ...\n",
      "  [ 9.80347861e-04  6.47154346e-04 -1.41193485e-03 ...  5.13509382e-04\n",
      "    1.26405549e-03  5.65598195e-04]\n",
      "  [ 9.17058846e-04  2.50233058e-03  4.42445651e-03 ... -1.58817333e-03\n",
      "   -1.50436477e-03 -8.17081658e-04]\n",
      "  [ 1.73702615e-03 -9.79942735e-04  2.01910804e-03 ... -2.94973986e-04\n",
      "   -1.92856113e-03 -1.22110255e-03]]\n",
      "\n",
      " [[ 1.65159523e-03 -7.83543277e-04 -1.34161417e-03 ... -3.77873715e-04\n",
      "   -7.50854320e-04 -1.53106754e-03]\n",
      "  [-9.80450655e-04  2.33743247e-03  2.21673446e-03 ... -9.08568851e-04\n",
      "   -9.97065334e-04 -2.04751780e-03]\n",
      "  [ 2.41016992e-03  2.79845321e-03  2.00319965e-03 ... -2.86719319e-03\n",
      "   -2.00457452e-03 -5.74408099e-04]\n",
      "  ...\n",
      "  [ 3.41372390e-04  7.62945274e-04  1.54492143e-03 ... -1.77225389e-03\n",
      "   -1.66200032e-03  1.85312040e-03]\n",
      "  [ 1.44252344e-03  1.57906266e-03  5.29245808e-05 ... -9.32795927e-04\n",
      "   -9.69063025e-04  2.16085260e-04]\n",
      "  [ 9.17058846e-04  2.50233058e-03  4.42445651e-03 ... -1.58817333e-03\n",
      "   -1.50436477e-03 -8.17081658e-04]]\n",
      "\n",
      " [[ 1.85412506e-03  6.56488293e-04  1.95969408e-03 ... -1.62754662e-03\n",
      "   -3.65291024e-04  1.11555075e-03]\n",
      "  [-1.16380327e-03  1.97835756e-03  1.94186973e-03 ... -4.90576029e-04\n",
      "    9.56101867e-04 -2.17272609e-04]\n",
      "  [-5.55441715e-04  1.32766596e-04  3.65803193e-04 ...  4.09101543e-04\n",
      "   -2.54563452e-03 -1.51056645e-03]\n",
      "  ...\n",
      "  [ 1.09629496e-03  1.81952701e-03 -5.54577506e-04 ...  3.80016252e-04\n",
      "   -1.75976160e-03 -1.29658054e-03]\n",
      "  [ 2.20210059e-03  5.58334687e-05  3.15215462e-03 ... -2.62293412e-04\n",
      "   -1.33448991e-03 -1.39197800e-03]\n",
      "  [ 1.62084401e-03 -7.79598893e-04  1.90973911e-03 ... -7.03808561e-04\n",
      "    1.30746665e-03 -2.05009500e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.65787013e-03 -9.76285897e-04  9.06087575e-04 ... -6.01873500e-04\n",
      "   -1.07749765e-04 -8.57963518e-04]\n",
      "  [ 1.27066777e-03 -9.19021899e-04 -6.11591153e-04 ... -5.91577438e-04\n",
      "   -2.54123751e-03  1.27323938e-03]\n",
      "  [-1.72497029e-03  1.37402886e-03  8.66845832e-04 ... -1.85498886e-03\n",
      "   -4.04417660e-04 -9.09946393e-04]\n",
      "  ...\n",
      "  [-1.16380327e-03  1.97835756e-03  1.94186973e-03 ... -4.90576029e-04\n",
      "    9.56101867e-04 -2.17272609e-04]\n",
      "  [-1.31374144e-03  5.98857470e-04 -1.50591368e-03 ...  8.31883808e-04\n",
      "   -6.19728817e-04  1.78180484e-03]\n",
      "  [-1.65787013e-03 -9.76285897e-04  9.06087575e-04 ... -6.01873500e-04\n",
      "   -1.07749765e-04 -8.57963518e-04]]\n",
      "\n",
      " [[ 1.27066777e-03 -9.19021899e-04 -6.11591153e-04 ... -5.91577438e-04\n",
      "   -2.54123751e-03  1.27323938e-03]\n",
      "  [-1.72497029e-03  1.37402886e-03  8.66845832e-04 ... -1.85498886e-03\n",
      "   -4.04417660e-04 -9.09946393e-04]\n",
      "  [ 2.41016992e-03  2.79845321e-03  2.00319965e-03 ... -2.86719319e-03\n",
      "   -2.00457452e-03 -5.74408099e-04]\n",
      "  ...\n",
      "  [-4.89065715e-05  1.42475532e-03  1.68155413e-03 ... -1.18127442e-03\n",
      "    7.70567160e-04  7.03823287e-04]\n",
      "  [ 1.12171995e-03 -6.45502703e-04 -1.55348424e-03 ... -1.91302656e-03\n",
      "   -6.58592733e-04 -8.64330679e-04]\n",
      "  [ 2.32190778e-03  1.71176845e-03  4.36209561e-03 ... -4.30510292e-04\n",
      "   -2.68726377e-03  7.37072027e-04]]\n",
      "\n",
      " [[ 4.72834188e-04 -7.00734323e-04  2.31847377e-03 ... -6.81826612e-04\n",
      "    9.77390911e-04  4.44196776e-04]\n",
      "  [ 5.86746319e-04 -9.69838933e-04  3.82659171e-04 ...  1.61831523e-03\n",
      "    1.02558243e-03 -1.18653267e-03]\n",
      "  [ 9.05377383e-04 -9.39553662e-04  2.03326996e-03 ...  1.71043235e-03\n",
      "   -7.12743902e-04 -1.64949428e-03]\n",
      "  ...\n",
      "  [ 2.02994817e-03 -3.06506059e-04 -1.55524211e-03 ...  5.43357397e-04\n",
      "   -2.04037200e-03  6.07998983e-04]\n",
      "  [ 9.24843655e-04  2.27526063e-03 -5.99806721e-04 ...  8.92295793e-04\n",
      "    5.23636176e-04 -1.02998700e-03]\n",
      "  [-5.55441715e-04  1.32766596e-04  3.65803193e-04 ...  4.09101543e-04\n",
      "   -2.54563452e-03 -1.51056645e-03]]]\n"
     ]
    }
   ],
   "source": [
    "input_vector_sequence = []\n",
    "window_size = 10\n",
    "input_processed_data = [item for sublist in processed_data for item in sublist]\n",
    "\n",
    "for index in range(0, len(input_processed_data), window_size):\n",
    "\n",
    "    seq = input_processed_data[index:index+window_size]\n",
    "\n",
    "    if len(seq) == window_size and all(word in text_model.wv for word in seq):\n",
    "        input_vector_sequence.append([text_model.wv[word] for word in seq])\n",
    "\n",
    "final_input = np.array(input_vector_sequence)\n",
    "\n",
    "print(final_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 10, 500)\n",
      "2960\n",
      "296\n",
      "296\n"
     ]
    }
   ],
   "source": [
    "print(final_input.shape)\n",
    "print(len(input_processed_data))\n",
    "\n",
    "X = [seq[:-1] for seq in final_input]\n",
    "Y = [seq[-1] for seq in final_input]\n",
    "\n",
    "print(len(X))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Now we have our inputs ready we can build transformer for chatbot```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 9, 500)\n",
      "(296, 500)\n",
      "Epoch 1/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 313ms/step - accuracy: 0.0597 - loss: -0.0258\n",
      "Epoch 2/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 284ms/step - accuracy: 0.1976 - loss: -0.0240\n",
      "Epoch 3/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 270ms/step - accuracy: 0.1976 - loss: -0.0241\n",
      "Epoch 4/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 269ms/step - accuracy: 0.1976 - loss: -0.0242\n",
      "Epoch 5/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271ms/step - accuracy: 0.1976 - loss: -0.0243\n",
      "Epoch 6/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.1976 - loss: -0.0244\n",
      "Epoch 7/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271ms/step - accuracy: 0.1976 - loss: -0.0245\n",
      "Epoch 8/8\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271ms/step - accuracy: 0.1976 - loss: -0.0246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fd9c8712d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MultiHeadAttention, Dropout, Input, Dense, LayerNormalization, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, ff_size, embedding_dim, num_heads=3, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_size, activation='relu'), Dense(embedding_dim),]\n",
    "        )\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        # First attention and feed-forward block\n",
    "        attn_output = self.att(inputs, inputs, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        # Second attention and feed-forward block\n",
    "        attn_output2 = self.att(out2, out2, training=training)\n",
    "        attn_output2 = self.dropout1(attn_output2, training=training)\n",
    "        out3 = self.layernorm1(out2 + attn_output2)\n",
    "        ffn_output2 = self.ffn(out3)\n",
    "        ffn_output2 = self.dropout2(ffn_output2, training=training)\n",
    "        out4 = self.layernorm2(out3 + ffn_output2)\n",
    "\n",
    "        # Third attention and feed-forward block\n",
    "        attn_output3 = self.att(out4, out4, training=training)\n",
    "        attn_output3 = self.dropout1(attn_output3, training=training)\n",
    "        out5 = self.layernorm1(out4 + attn_output3)\n",
    "        ffn_output3 = self.ffn(out5)\n",
    "        ffn_output3 = self.dropout2(ffn_output3, training=training)\n",
    "        out6 = self.layernorm2(out5 + ffn_output3)\n",
    "\n",
    "        return out6\n",
    "\n",
    "def create_model(embed_dim, num_heads, ff_dim, input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    block = TransformerBlock(embedding_dim=embed_dim, num_heads=num_heads, ff_size=ff_dim)\n",
    "    x = block(inputs, training=True)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(20, activation='relu')(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "window_size =9\n",
    "embed_dim = 500 \n",
    "num_heads = 2  \n",
    "ff_dim = 36  \n",
    "input_shape = (window_size, embed_dim)  # Shape of the input\n",
    "num_classes = 500  # Number of classes (same as embedding dimension)\n",
    "\n",
    "# Preparing X and Y\n",
    "X = np.array([seq[:-1] for seq in final_input])\n",
    "Y = np.array([seq[-1] for seq in final_input])\n",
    "\n",
    "print(X.shape)  \n",
    "print(Y.shape)  \n",
    "\n",
    "# Create TensorFlow dataset\n",
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X, Y)).batch(batch_size)\n",
    "\n",
    "model = create_model(embed_dim, num_heads, ff_dim, input_shape=input_shape)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model using the dataset\n",
    "model.fit(dataset, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sequence is [[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 4.22459634e-05 -1.37545203e-03  1.93910568e-03 ... -1.16540515e-03\n",
      "   -3.17872298e-04  1.44207675e-03]\n",
      "  ...\n",
      "  [-1.65787013e-03 -9.76285897e-04  9.06087575e-04 ... -6.01873500e-04\n",
      "   -1.07749765e-04 -8.57963518e-04]\n",
      "  [ 1.27066777e-03 -9.19021899e-04 -6.11591153e-04 ... -5.91577438e-04\n",
      "   -2.54123751e-03  1.27323938e-03]\n",
      "  [-1.72497029e-03  1.37402886e-03  8.66845832e-04 ... -1.85498886e-03\n",
      "   -4.04417660e-04 -9.09946393e-04]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Next word prediction: fun\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(model, word2vec_model, text, window_size):\n",
    "    tokenized_text = simple_preprocess(text)\n",
    "    sequence = np.array([word2vec_model.wv[word] for word in tokenized_text[-window_size:] if word in word2vec_model.wv])\n",
    "    if len(sequence) < window_size:\n",
    "        sequence = np.pad(sequence, ((window_size - len(sequence), 0), (0, 0)), mode='constant')\n",
    "    sequence = sequence.reshape(1, window_size, -1)\n",
    "    print(\"The sequence is\",sequence)\n",
    "    preds = model.predict(sequence)\n",
    "    next_word_vector = preds[0]\n",
    "    # print(next_word_vector)\n",
    "    next_word = word2vec_model.wv.similar_by_vector(next_word_vector, topn=1)[0][0]\n",
    "    return next_word\n",
    "\n",
    "input_text = \"love it if it wasn't always so unpredictable \"\n",
    "predicted_word = predict_next_word(model, text_model, input_text, window_size)\n",
    "print(f\"Next word prediction: {predicted_word}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
